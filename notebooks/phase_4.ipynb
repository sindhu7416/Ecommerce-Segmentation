{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7bb0004",
   "metadata": {},
   "source": [
    "# Phase 4: Predictive Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89517ca2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve\n",
    "import shap\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b579fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load clustered data from Phase 3\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclustered_customers.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load clustered data from Phase 3\n",
    "df = pd.read_csv('clustered_customers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a17bad",
   "metadata": {},
   "source": [
    "# Prepare data with cluster features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9563a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base features (same as Phase 1)\n",
    "base_features = [\n",
    "    'Income', 'Customer_Tenure', 'Total_Spend', 'Family_Size', 'Recency',\n",
    "    'Education_encoded', 'Marital_Single', 'Marital_Married',\n",
    "    'MntWines', 'NumWebVisitsMonth'\n",
    "]\n",
    "\n",
    "# Add cluster features (one-hot encoded)\n",
    "clusters = pd.get_dummies(df['Cluster'], prefix='Segment')\n",
    "df = pd.concat([df, clusters], axis=1)\n",
    "\n",
    "# Final feature set\n",
    "features = base_features + clusters.columns.tolist()\n",
    "X = df[features]\n",
    "y = df['Response']  # Target variable\n",
    "\n",
    "# Train-test split (stratified by cluster)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=df['Cluster']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b763aa6",
   "metadata": {},
   "source": [
    "## SHAP Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SHAP values\n",
    "explainer = shap.TreeExplainer(best_rf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Handle binary classification SHAP values\n",
    "if isinstance(shap_values, list) and len(shap_values) == 2:\n",
    "    # Binary classification case\n",
    "    shap_values = shap_values[1]  # We want values for class 1 (positive response)\n",
    "elif len(shap_values.shape) == 3:\n",
    "    # Multi-class format, select class 1\n",
    "    shap_values = shap_values[:, :, 1]\n",
    "\n",
    "# Verify shapes match\n",
    "assert shap_values.shape == X_test.shape, \\\n",
    "    f\"SHAP values shape {shap_values.shape} doesn't match X_test shape {X_test.shape}\"\n",
    "\n",
    "#  Global Feature Importance (Matplotlib)\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
    "plt.title(\"Top Features Driving Campaign Response\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Individual Prediction Explanation (HTML)\n",
    "sample_idx = 0  # First test case\n",
    "shap.initjs()  # Initialize JS visualization\n",
    "force_plot = shap.force_plot(\n",
    "    explainer.expected_value[1],\n",
    "    shap_values[sample_idx, :],\n",
    "    X_test.iloc[sample_idx, :],\n",
    "    feature_names=X_test.columns.tolist(),\n",
    "    matplotlib=False\n",
    ")\n",
    "\n",
    "# Save interactive plot\n",
    "shap.save_html('shap_force_plot.html', force_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: Beeswarm Plot for Detailed Analysis\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_test, show=False)\n",
    "plt.title(\"Feature Impact on Campaign Response\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_beeswarm.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"SHAP outputs saved successfully:\")\n",
    "print(\"- Global feature importance: shap_feature_importance.png\")\n",
    "print(\"- Detailed impact analysis: shap_beeswarm.png\")\n",
    "print(\"- Interactive explanation: shap_force_plot.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a5c2de",
   "metadata": {},
   "source": [
    "## Response Probability by Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Response_Probability'] = best_rf.predict_proba(X)[:, 1]\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(\n",
    "    x='Cluster', \n",
    "    y='Response_Probability', \n",
    "    data=df,\n",
    "    order=sorted(df['Cluster'].unique()),\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Response Probability by Customer Segment', fontsize=14)\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Response Probability')\n",
    "plt.xticks(ticks=range(len(df['Cluster'].unique())),\n",
    "           labels=[f'Segment {i+1}' for i in sorted(df['Cluster'].unique())])\n",
    "plt.savefig('response_by_segment.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26408533",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0befa726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save probabilities with cluster info\n",
    "output_cols = ['ID', 'Cluster'] + features + ['Response_Probability']\n",
    "df[output_cols].to_csv('customers_with_predictions.csv', index=False)\n",
    "\n",
    "# Generate segment-level insights\n",
    "segment_stats = df.groupby('Cluster')['Response_Probability'].agg(\n",
    "    ['mean', 'median', 'std', 'count']\n",
    ").reset_index()\n",
    "segment_stats.columns = ['Segment', 'Avg_Prob', 'Median_Prob', 'Std_Prob', 'Count']\n",
    "segment_stats.to_csv('segment_response_stats.csv', index=False)\n",
    "\n",
    "print(\"\\nOutput Files Created:\")\n",
    "print(\"- rf_model_with_segments.pkl: Trained model\")\n",
    "print(\"- shap_*.png: SHAP interpretation plots\")\n",
    "print(\"- response_by_segment.png: Segment comparison\")\n",
    "print(\"- customers_with_predictions.csv: Full dataset with predictions\")\n",
    "print(\"- segment_response_stats.csv: Summary statistics by segment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
